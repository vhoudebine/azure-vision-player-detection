{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s.hdnux.com/photos/01/33/52/57/24030153/3/1200x0.jpg\n",
      "https://www.proballers.com/media/cache/resize_300/ul/player/backup/sans-titre-1-1ed9f42b-f622-6b96-89ba-3faf8e459635.jpg\n",
      "https://www.2kratings.com/wp-content/uploads/Victor-Wembanyama-2K-Rating.png\n",
      "https://d1l5jyrrh5eluf.cloudfront.net/wp-content/uploads/2022/10/VictorW_Watermarked_02.jpg\n",
      "https://eurospects.com/wp-content/uploads/2020/09/wembanyama.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# Use the bing image search API to search for pictures of players\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "api_key = os.getenv('BING_API_KEY')\n",
    "\n",
    "# Set the search query and other parameters\n",
    "search_query = 'Victor Wembanyama headshot'\n",
    "count = 5\n",
    "\n",
    "# API endpoint URL\n",
    "url = 'https://api.bing.microsoft.com/v7.0/images/search'\n",
    "\n",
    "# Set the headers with the API key\n",
    "headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "\n",
    "# Set the query parameters\n",
    "params = {\n",
    "    'q': search_query,\n",
    "    'count': count\n",
    "}\n",
    "\n",
    "# Make the API call\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Get the JSON response\n",
    "data = response.json()\n",
    "\n",
    "# Extract the image URLs from the response\n",
    "image_urls = [result['contentUrl'] for result in data['value']]\n",
    "\n",
    "# Print the image URLs\n",
    "for url in image_urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>Birth Date</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Exp</th>\n",
       "      <th>College</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Tre Jones</td>\n",
       "      <td>PG</td>\n",
       "      <td>6-1</td>\n",
       "      <td>185</td>\n",
       "      <td>January 8 2000</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Malaki Branham</td>\n",
       "      <td>PG</td>\n",
       "      <td>6-4</td>\n",
       "      <td>180</td>\n",
       "      <td>May 12 2003</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>Ohio State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Jeremy Sochan</td>\n",
       "      <td>PF</td>\n",
       "      <td>6-8</td>\n",
       "      <td>230</td>\n",
       "      <td>May 20 2003</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>Baylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Julian Champagnie</td>\n",
       "      <td>SF</td>\n",
       "      <td>6-8</td>\n",
       "      <td>220</td>\n",
       "      <td>June 29 2001</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>St. John's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Cedi Osman</td>\n",
       "      <td>SF</td>\n",
       "      <td>6-7</td>\n",
       "      <td>230</td>\n",
       "      <td>April 8 1995</td>\n",
       "      <td>mk</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.             Player Pos   Ht   Wt      Birth Date Unnamed: 6 Exp  \\\n",
       "0   33          Tre Jones  PG  6-1  185  January 8 2000         us   3   \n",
       "1   22     Malaki Branham  PG  6-4  180     May 12 2003         us   1   \n",
       "2   10      Jeremy Sochan  PF  6-8  230     May 20 2003         us   1   \n",
       "3   30  Julian Champagnie  SF  6-8  220    June 29 2001         us   1   \n",
       "4   16         Cedi Osman  SF  6-7  230    April 8 1995         mk   6   \n",
       "\n",
       "      College  \n",
       "0        Duke  \n",
       "1  Ohio State  \n",
       "2      Baylor  \n",
       "3  St. John's  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Sample table data with Spurs players names in CSV format\n",
    "\n",
    "table_str = \"\"\"No.,Player,Pos,Ht,Wt,Birth Date,,Exp,College\n",
    "33,Tre Jones,PG,6-1,185,January 8 2000,us,3,Duke\n",
    "22,Malaki Branham,PG,6-4,180,May 12 2003,us,1,Ohio State\n",
    "10,Jeremy Sochan,PF,6-8,230,May 20 2003,us,1,Baylor\n",
    "30,Julian Champagnie,SF,6-8,220,June 29 2001,us,1,St. John's\n",
    "16,Cedi Osman,SF,6-7,230,April 8 1995,mk,6,\n",
    "1,Victor Wembanyama,C,7-4,209,January 4 2004,fr,R,\n",
    "3,Keldon Johnson,SF,6-5,220,October 11 1999,us,4,Kentucky\n",
    "23,Zach Collins,C,6-11,250,November 19 1997,us,5,Gonzaga\n",
    "24,Devin Vassell,SG,6-5,200,August 23 2000,us,3,Florida State\n",
    "14,Blake Wesley,SG,6-5,185,March 16 2003,us,1,Notre Dame\n",
    "54,Sandro Mamukelashvili,C,6-11,240,May 23 1999,us,2,Seton Hall\n",
    "26,Dominick Barlow,PF,6-9,221,May 26 2003,us,1,\n",
    "4,Devonte' Graham,PG,6-1,195,February 22 1995,us,5,Kansas\n",
    "28,Charles Bassey,C,6-10,235,October 28 2000,ng,2,Western Kentucky\n",
    "25,Sidy Cissoko,SF,6-8,200,April 2 2004,fr,R,\n",
    "7,David Duke Jr.  (TW),SG,6-5,205,October 13 1999,us,2,Providence\n",
    "41,RaiQuan Gray  (TW),PF,6-8,260,July 7 1999,us,1,Florida State\n",
    "15,Jamaree Bouyea  (TW),PG,6-2,180,June 27 1999,us,1,San Francisco\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(table_str), sep=',', header=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: nbaplayers\n",
      "Person group nbaplayers already exists.\n",
      "Skipping Tre Jones as it already exists.\n",
      "Skipping Malaki Branham as it already exists.\n",
      "Skipping Jeremy Sochan as it already exists.\n",
      "Skipping Julian Champagnie as it already exists.\n",
      "Skipping Cedi Osman as it already exists.\n",
      "Skipping Victor Wembanyama as it already exists.\n",
      "Skipping Keldon Johnson as it already exists.\n",
      "Skipping Zach Collins as it already exists.\n",
      "Skipping Devin Vassell as it already exists.\n",
      "Skipping Blake Wesley as it already exists.\n",
      "Creating person for Sandro Mamukelashvili...\n",
      "Creating person for Dominick Barlow...\n",
      "Creating person for Devonte' Graham...\n",
      "Creating person for Charles Bassey...\n",
      "Creating person for Sidy Cissoko...\n",
      "Creating person for David Duke Jr.  (TW)...\n",
      "Creating person for RaiQuan Gray  (TW)...\n",
      "Creating person for Jamaree Bouyea  (TW)...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition\n",
    "import time\n",
    "\n",
    "\n",
    "FACES_API_KEY = os.getenv('FACES_API_KEY')\n",
    "FACES_ENDPOINT = os.getenv('FACES_ENDPOINT')\n",
    "PERSON_GROUP_ID = \"nbaplayers\" # assign a random ID (or name it anything)\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(FACES_ENDPOINT,\n",
    "                        CognitiveServicesCredentials(FACES_API_KEY))\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "person_groups = [group.name for group in face_client.person_group.list()]\n",
    "if PERSON_GROUP_ID in person_groups:\n",
    "    print(f\"Person group {PERSON_GROUP_ID} already exists.\")\n",
    "else:\n",
    "    print(f\"Creating person group {PERSON_GROUP_ID}...\")\n",
    "    face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
    "\n",
    "\n",
    "# Retry parameters\n",
    "max_retries = 3\n",
    "retry_delay = 2  # seconds\n",
    "\n",
    "existing_players = [player.name for player in face_client.person_group_person.list('nbaplayers')]\n",
    "\n",
    "# Retry loop\n",
    "for player in df['Player'].tolist():\n",
    "    if player in existing_players:\n",
    "        print(f\"Skipping {player} as it already exists.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Creating person for {player}...\")\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                face_client.person_group_person.create(PERSON_GROUP_ID, name=player)\n",
    "                break  # Exit the loop if create() succeeds\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating person: {e}\")\n",
    "                retries += 1\n",
    "                if retries < max_retries:\n",
    "                    print(f\"Retrying after {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    print(\"Max retries reached. Skipping person creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_images(search_query, count):\n",
    "    # Replace 'YOUR_API_KEY' with your actual API key\n",
    "    api_key = os.getenv('BING_API_KEY')\n",
    "\n",
    "    # API endpoint URL\n",
    "    url = 'https://api.bing.microsoft.com/v7.0/images/search'\n",
    "\n",
    "    # Set the headers with the API key\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "\n",
    "    # Set the query parameters\n",
    "    params = {\n",
    "        'q': search_query,\n",
    "        'count': count\n",
    "    }\n",
    "\n",
    "    # Make the API call\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    # Get the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the image URLs from the response\n",
    "    image_urls = [result['contentUrl'] for result in data['value']]\n",
    "\n",
    "    # Return the image URLs\n",
    "    return image_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['faces'] = df['Player'].apply(lambda x: search_images(f\"{x} Spurs headshot\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Devin Vassell': '073485f2-01fd-4f82-8598-ac9de142f45f', 'David Duke Jr.  (TW)': '07f9191a-69e8-4765-8331-3266987e917b', 'Zach Collins': '1a6bcdaf-6727-4182-8527-2bc72642ef3c', 'Julian Champagnie': '5391e31e-dacb-4e65-8aa6-abca254d371f', 'Jeremy Sochan': '55241cf6-4ab0-4368-9bd0-8c73a0839b51', 'Sandro Mamukelashvili': '55822fb9-454d-4fb1-994b-d97e4a0cc6bc', 'RaiQuan Gray  (TW)': '6667bd63-ec71-4a7d-8f5b-9dfad909266a', 'Victor Wembanyama': '7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce', 'Malaki Branham': '83dc1aa7-f462-4e25-b5d7-7dadb20d6031', 'Charles Bassey': '8b7422d7-d933-4bb0-9d56-94a64c3eddd9', 'Jamaree Bouyea  (TW)': 'b80001dd-4019-4c23-8c8b-450d9d1442d5', 'Keldon Johnson': 'c113a765-a62d-4f79-9df6-7d04ff23dcac', 'Tre Jones': 'c6ec5ac4-cc0c-4986-ab80-37836007c456', 'Dominick Barlow': 'c92783d2-ae7e-4947-a972-be2e245b092a', 'Cedi Osman': 'c969c722-cf66-44e5-9c1a-2434dc3c3453', 'Blake Wesley': 'e33fe7e8-f038-4cf0-af1e-18acaa663d4e', \"Devonte' Graham\": 'ed385e26-214f-49af-a05d-731d1a339d4d', 'Sidy Cissoko': 'f8ada502-ffaa-469d-9908-c70d7efa1853'}\n"
     ]
    }
   ],
   "source": [
    "pers_dict = {}\n",
    "for pers in face_client.person_group_person.list('nbaplayers'):\n",
    "    pers_dict[pers.name]= pers.person_id\n",
    "\n",
    "print(pers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['person_id'] = df['Player'].apply(lambda x: pers_dict[x] if x in pers_dict else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_faces_to_person(face_client, person_group_id, person_id, image_urls):\n",
    "    for image_url in image_urls:\n",
    "        sufficientQuality = True\n",
    "        detected_faces = face_client.face.detect_with_url(url=image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "        for face in detected_faces:\n",
    "            if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "                sufficientQuality = False\n",
    "                print(\"{} has insufficient quality\".format(face))\n",
    "                break\n",
    "            try:\n",
    "                face_client.person_group_person.add_face_from_url(person_group_id, person_id, image_url)\n",
    "                print(\"face {} added to person {}\".format(face.face_id, person_id))\n",
    "            except:\n",
    "                continue\n",
    "        if not sufficientQuality: continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face 6837896c-261d-4163-aee4-6cfb0a327f07 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "face 4bdc1887-cef5-4322-80de-44613078a30c added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "face 514d604c-a88f-4b2c-85ec-8ec90c7157b4 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "face 2be11b1c-0791-40b6-bd0d-87af76230a21 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "face 37720a70-e77c-4873-9fea-64f5716b0517 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "{'additional_properties': {}, 'face_id': 'bab073e9-96e2-4e0c-ac7f-6662f2283926', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1b3f5490>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1b3f4790>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '2a43c21c-51ea-4c99-9937-2d46475b3edc', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1be16a90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1be14590>} has insufficient quality\n",
      "face f98f4cf2-dce6-467a-8eb8-6f3d2bfc32b5 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "face c329eb6a-3cb7-4eef-a020-edd9bd2b2e86 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "face c1d2fa46-4de2-418b-b9d2-fdb0e0b88ef3 added to person c6ec5ac4-cc0c-4986-ab80-37836007c456\n",
      "{'additional_properties': {}, 'face_id': 'd67ba587-d984-4ea4-9dec-290cbb8d2105', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a278e10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27a490>} has insufficient quality\n",
      "face d34d4b12-9473-4d01-8739-875407550be6 added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "face fe59f3a3-6b42-40c3-9ad1-987459ff5896 added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "face a04f4e9f-41ab-4df5-b046-6c091ac07e6d added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "face 12b76571-33db-444f-9a32-bdaf2b55f194 added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "{'additional_properties': {}, 'face_id': 'f463aecb-6897-4892-9a44-af44f03be795', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a26a210>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a269dd0>} has insufficient quality\n",
      "face f7f01d57-e6c9-4abe-b108-b95de1c9e63a added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "{'additional_properties': {}, 'face_id': '89108dc8-3935-46d5-81da-50a82830d9c5', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29d310>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29d710>} has insufficient quality\n",
      "face 9ea5d60b-bb20-4a4a-aedb-09fcbc389fef added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "{'additional_properties': {}, 'face_id': 'e1710a10-bbc3-4f9b-9720-f69bbc697b6b', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1b3f5bd0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1b3f6910>} has insufficient quality\n",
      "face e977b9d5-eb8d-4d32-abc8-5a43606ca9af added to person 83dc1aa7-f462-4e25-b5d7-7dadb20d6031\n",
      "face afc41ff3-62ed-4fea-895d-ac7429526c8e added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "face 52385953-a074-4c44-b603-3456c86fed84 added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "face e974dc5d-af36-473f-b61a-e017ac478e1f added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "{'additional_properties': {}, 'face_id': 'cebecef9-816c-4206-be8a-08c5c77eedfe', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29ccd0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29d5d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '3b373d64-e171-492e-b83c-e042720f9637', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a27bf50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27a110>} has insufficient quality\n",
      "face 8e781b97-e439-4d0b-af51-ac0679473ab2 added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "face e1fc1820-2673-4649-9375-551400191cab added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "{'additional_properties': {}, 'face_id': 'ffacbc2d-eb4c-4803-853f-4001dee5c0a8', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a278190>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27a790>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '0d45b9ef-c0b8-4045-9876-ed2737152f00', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a25f350>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a25c350>} has insufficient quality\n",
      "face d521b8a5-1408-4a72-9c22-46e510b3b737 added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "{'additional_properties': {}, 'face_id': 'cff76d7c-1033-46b7-9987-5ec42c51784b', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a256050>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a254350>} has insufficient quality\n",
      "face 1f750b21-8c5b-4346-9418-ce72ffb65303 added to person 55241cf6-4ab0-4368-9bd0-8c73a0839b51\n",
      "face 9c949e73-73b1-4d87-b023-ce3155518895 added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "face 0c7394b4-11a0-4d33-b458-0f1bac973076 added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "face 257eab9f-459b-4b16-a4d7-ceefa891bad4 added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "face aae21926-59aa-4df8-aa5c-84216c04b061 added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "{'additional_properties': {}, 'face_id': '38c8edac-524b-4ef5-acb0-522bae7942f9', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2c0e10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2c1fd0>} has insufficient quality\n",
      "face 9e757405-9880-4a7c-9b95-435c29aa625e added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "{'additional_properties': {}, 'face_id': '3f1c377c-e029-4e41-8715-502edcc4b996', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29e190>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29fe90>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '0cb3c1a8-6497-46db-ba7d-7bd5fe116762', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2690d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a256810>} has insufficient quality\n",
      "face 09402128-060b-4d50-b753-39b6c6ee725c added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "{'additional_properties': {}, 'face_id': 'd167b815-937c-4952-a61b-3218a0f3b28a', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1b3f6a90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1b3f5250>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '57e51e31-3527-4895-a0b5-ed4c6d0a4f6a', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a274e10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a277610>} has insufficient quality\n",
      "face fb57ceea-7f4e-4a28-8816-83fdf4cb7021 added to person 5391e31e-dacb-4e65-8aa6-abca254d371f\n",
      "face 863b0571-887b-4401-b1c4-25125627dd6e added to person c969c722-cf66-44e5-9c1a-2434dc3c3453\n",
      "face 78aa3c05-ee00-4d79-aaf2-f1d7f37cafdc added to person c969c722-cf66-44e5-9c1a-2434dc3c3453\n",
      "{'additional_properties': {}, 'face_id': '4b30ad47-7cde-41ad-9662-a22cfc68649f', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2c17d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2c1a90>} has insufficient quality\n",
      "face 8a1e6d8f-de72-4245-9469-4ca5535bfbaa added to person c969c722-cf66-44e5-9c1a-2434dc3c3453\n",
      "{'additional_properties': {}, 'face_id': 'b0371a8a-10f0-471e-85f9-3eb65fdf03c4', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b4f90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b7350>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '7f478a30-a585-4d25-8404-52d9e18afa6a', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a250d10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a253a90>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '2c0a3087-36c4-48b2-95ef-14f0ad3f07e2', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29d990>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29f590>} has insufficient quality\n",
      "face 9dc8438e-43a0-4051-b882-5b5edd52995e added to person c969c722-cf66-44e5-9c1a-2434dc3c3453\n",
      "{'additional_properties': {}, 'face_id': '1e861c3d-16c3-41f8-9179-34047b638628', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a27bed0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a279250>} has insufficient quality\n",
      "face 2e550716-d900-48aa-99f3-9ee3fb23fc21 added to person c969c722-cf66-44e5-9c1a-2434dc3c3453\n",
      "{'additional_properties': {}, 'face_id': 'eb5aef8e-6324-4f3e-b5bf-fc558704f036', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a276b90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a274690>} has insufficient quality\n",
      "face db99c83a-d407-401d-8cb6-4b577c1c52b4 added to person c969c722-cf66-44e5-9c1a-2434dc3c3453\n",
      "{'additional_properties': {}, 'face_id': '494fdab4-62a2-467e-a89f-c8c3f3569be0', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1b3f5250>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1b3f7310>} has insufficient quality\n",
      "face 9ce170d5-a47e-4fe7-b612-5d67778e7a79 added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "face c48458c6-6c13-4f43-8648-360744096793 added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "face 0551df2e-1596-4c8c-ac78-c0a2f6ec0db9 added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "face e6bd83b5-3821-49de-8106-caaf4aa1e391 added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "face 6543928f-75ff-4da3-a389-ef6294a8821a added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "face ad2cf48d-2f72-4b15-81c3-c38a04544e8b added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "{'additional_properties': {}, 'face_id': 'a33f12bf-b8b7-4b69-8f04-693be44a8534', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29ec50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29e590>} has insufficient quality\n",
      "face 20d538a1-5efd-43a9-8d5b-7f02d8a5f2ae added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "{'additional_properties': {}, 'face_id': 'ed4cdcd8-d311-46e4-b2a0-832934d6bea7', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b79d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b5550>} has insufficient quality\n",
      "face ea97da76-5333-4c21-90cd-75a20bf58b7a added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "{'additional_properties': {}, 'face_id': 'db141660-8079-45cc-88a4-0e068514ab5d', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a3c4810>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a3c5d10>} has insufficient quality\n",
      "face 0a6b7476-40b9-480a-a102-d406b26e4b2f added to person 7ae200de-32e6-4f80-9ef3-6ec19fe1b1ce\n",
      "face ffcd8394-352b-4a09-9cc7-0a313238458a added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "face 9f2485f3-d99e-44e7-9ce5-95409871c776 added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "face 9d3cf3a6-2662-4bfd-b539-b8b25cca51b9 added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "{'additional_properties': {}, 'face_id': '384d34c8-a42e-4047-af50-4aec43d4057c', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a274490>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a276cd0>} has insufficient quality\n",
      "face c0491139-82fd-4d21-b102-fa94f4538730 added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "{'additional_properties': {}, 'face_id': '4f3878c1-acae-4f28-92c4-d53c5c8484a7', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a278c90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27b910>} has insufficient quality\n",
      "face e63768a6-32b0-427d-8dab-4e220890295f added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "{'additional_properties': {}, 'face_id': '3680ea04-33f8-4b52-931c-3f20d47c4ab0', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2fcd10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2ff0d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': 'cc6a0587-93c7-4c1f-8cae-8b3070fd2a3f', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1b3f67d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1b3f6c90>} has insufficient quality\n",
      "face de88e264-fee5-4418-b5bd-c88e42c8e3b6 added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "{'additional_properties': {}, 'face_id': 'b1628aed-670a-44d6-8972-5ebf2fd6fe92', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a50bb10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a50a0d0>} has insufficient quality\n",
      "face ad671699-f2b1-47d6-b668-a08e17f8844b added to person c113a765-a62d-4f79-9df6-7d04ff23dcac\n",
      "{'additional_properties': {}, 'face_id': '2ed8f625-e8a0-4dda-ac0b-704de2e6cccc', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a276390>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a275a90>} has insufficient quality\n",
      "face 2566f810-1e24-4169-bfc3-6fa30dda3d51 added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "face 0a94b77e-e2bb-4006-9f0b-73b192464871 added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "face 1f67f3c0-6705-441f-b07c-0c1332a7fed9 added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "face c1029ab5-4794-404e-b50c-f57ad48439ff added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "{'additional_properties': {}, 'face_id': '75aa3a9c-766f-4665-81d2-928ebe2a1d81', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a26f390>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a26d2d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': 'aaced993-0100-4c71-8c69-81ee9aaa6edc', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a3a1490>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a3a0e90>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '904a64f5-0add-4d39-aa07-d92f714ff85b', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b70d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b7290>} has insufficient quality\n",
      "face e87f514b-76ec-4e85-869b-af33f722e3f8 added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "face f6800113-55dc-4349-8361-2c150c17cfa5 added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "face 02f5dc10-762c-4495-b692-8bab7402392c added to person 1a6bcdaf-6727-4182-8527-2bc72642ef3c\n",
      "face 360cf19e-238c-4a8e-99d9-31e4448ac500 added to person 073485f2-01fd-4f82-8598-ac9de142f45f\n",
      "face 24a8b34c-ae67-48a7-8488-495dd66f18f2 added to person 073485f2-01fd-4f82-8598-ac9de142f45f\n",
      "{'additional_properties': {}, 'face_id': 'e7f920d9-669f-4a42-b7f8-46b72cafa935', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a26f490>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a26fcd0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '40d98aa9-de26-4b62-ad4e-d50df48b9037', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2518d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2519d0>} has insufficient quality\n",
      "face 709de677-7f72-4173-9af1-337f2f5427d8 added to person 073485f2-01fd-4f82-8598-ac9de142f45f\n",
      "face fd16b8c4-f508-4b35-aca2-6a5b5b245a69 added to person 073485f2-01fd-4f82-8598-ac9de142f45f\n",
      "{'additional_properties': {}, 'face_id': '770a4120-398d-4ded-94d4-d56fb9205516', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a275e10>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a275150>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': 'ff30fa47-91cf-4696-942d-536003326635', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29c250>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29e950>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '5fd942c0-184a-491f-9b38-6e59499c9381', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a278190>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27a7d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '0eb44723-d911-4ab1-925a-80d120d8f426', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b5b50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b4b90>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '5c539cc1-3f98-46f2-acdd-cca8c30b122e', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29cc50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29e790>} has insufficient quality\n",
      "face 0330ced9-43eb-4902-845a-b45c4d02492f added to person e33fe7e8-f038-4cf0-af1e-18acaa663d4e\n",
      "face 82c4d7bf-29c6-4475-85f5-c6d2b2b6800d added to person e33fe7e8-f038-4cf0-af1e-18acaa663d4e\n",
      "face e4de44aa-3ce6-44de-8f16-70f948167bf5 added to person e33fe7e8-f038-4cf0-af1e-18acaa663d4e\n",
      "face c58edc0d-e451-4639-949e-9f5ce6900b3c added to person e33fe7e8-f038-4cf0-af1e-18acaa663d4e\n",
      "{'additional_properties': {}, 'face_id': '8d387a0d-9c67-4275-bbff-699787c8a994', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b51254f50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a319890>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '1ed2e96d-19ea-4beb-b3c7-9c338ba1bd76', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b6e90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b7e50>} has insufficient quality\n",
      "face cdc5f859-e82a-441e-be23-754b329b11e2 added to person e33fe7e8-f038-4cf0-af1e-18acaa663d4e\n",
      "face b040b837-e7f4-482f-ad5c-01b70e50a001 added to person e33fe7e8-f038-4cf0-af1e-18acaa663d4e\n",
      "{'additional_properties': {}, 'face_id': '0e8d8198-1170-4268-b6a6-2ef0bc77f3b4', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a253010>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1b3ea750>} has insufficient quality\n",
      "face 37a2634f-ff79-4515-9e53-f844ac0f2a0e added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face b79db532-4755-4a9c-b03d-9d4c3d98b103 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face c86ff309-4be6-4d8d-91a1-914c52201a24 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face a1c6e0bb-481d-4948-a8a3-e822d67e4e1c added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "{'additional_properties': {}, 'face_id': '22a04f7c-42f0-489d-b196-15c94ab82a72', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1bd8b810>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1bd8a510>} has insufficient quality\n",
      "face d2dcd05f-ac91-4d2a-9d35-4a235af94d1e added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face 1f602578-8373-4847-8f5d-84b4ecbae3e0 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "{'additional_properties': {}, 'face_id': 'a2741788-e272-4e57-86eb-e89a9ab02605', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1be14610>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1be15210>} has insufficient quality\n",
      "face db6d4df8-5ec4-4446-a125-244047304d67 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "{'additional_properties': {}, 'face_id': 'c05a6984-d3c2-4d63-86c6-d55adcc78b6f', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a1ed0d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a1ee790>} has insufficient quality\n",
      "face 0c24b591-6444-4a48-a4de-b6541dc15215 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face b12348c2-a74c-4c0e-8a51-26cccbfe3c60 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face 46ca5b21-c07b-417a-916d-107d45e2a0c0 added to person 55822fb9-454d-4fb1-994b-d97e4a0cc6bc\n",
      "face 04708c30-9dad-459f-9218-72047330dbde added to person c92783d2-ae7e-4947-a972-be2e245b092a\n",
      "face 9bc8b15e-7c67-48c1-bff2-f952a387e9f6 added to person c92783d2-ae7e-4947-a972-be2e245b092a\n",
      "{'additional_properties': {}, 'face_id': '3ad1108a-925c-461a-9446-97c6db82c925', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b502327d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2f7e90>} has insufficient quality\n",
      "face 4f25aefd-0e1a-4a5a-8b49-49ae07e30db2 added to person c92783d2-ae7e-4947-a972-be2e245b092a\n",
      "{'additional_properties': {}, 'face_id': 'a76cc218-03bf-4129-a586-5861a784c514', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29f610>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29d790>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '20fb3450-9f44-4a40-aa61-cfb604d77c7b', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29fd50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29d350>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '63ff5ca6-81ac-4e4c-99e1-be303daa3bd9', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29e190>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29df10>} has insufficient quality\n",
      "face a623f023-4143-4745-af39-2ac5f60ee2f7 added to person c92783d2-ae7e-4947-a972-be2e245b092a\n",
      "face 71945a98-9229-4545-a2e0-4070831bf4a5 added to person c92783d2-ae7e-4947-a972-be2e245b092a\n",
      "{'additional_properties': {}, 'face_id': '1d7b50ca-0343-48ae-b909-dbfd8d8766a3', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a3c4c50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a3c6510>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '507d0786-e19c-4153-a6d4-81de75f771a8', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1bd56550>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1bd56110>} has insufficient quality\n",
      "face 95b572a4-6d28-43b2-b65c-3977959b81af added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "face c05ee1ff-6ed4-43e0-b023-de6d09bd3e14 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "face bf56b086-ef45-4c64-8fea-c7c573f53d81 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "face ab7879df-a426-461f-b594-59b17ac95413 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "face 490ce487-b765-4c46-aaf6-33fd53c157f7 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "{'additional_properties': {}, 'face_id': 'd03aabbc-4986-413d-8694-bfbbd4622a05', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29e990>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29f350>} has insufficient quality\n",
      "face 013a63bb-05ee-4d9f-a77e-8e46b6f1a8f5 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "face c761813e-8dfb-48a7-93a5-47e6f976e868 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "{'additional_properties': {}, 'face_id': '97ab8bfa-1c32-4ae3-a0af-05247b0fc0d9', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b6790>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b55d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '17808c80-b333-41af-bc66-ee545e25fbff', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29d010>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29da90>} has insufficient quality\n",
      "face 6af8ecd7-bba1-4ff8-9bb6-ad504a156d76 added to person ed385e26-214f-49af-a05d-731d1a339d4d\n",
      "face 5e43647f-605a-4e27-87c2-518c471b1ee3 added to person 8b7422d7-d933-4bb0-9d56-94a64c3eddd9\n",
      "{'additional_properties': {}, 'face_id': 'e51dd8bd-62e5-47f5-aece-64e4c475a4bf', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a275950>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a275c50>} has insufficient quality\n",
      "face e62b18a3-fbb4-4d09-a642-be7fcd3ff8a8 added to person 8b7422d7-d933-4bb0-9d56-94a64c3eddd9\n",
      "{'additional_properties': {}, 'face_id': '4c1775d7-040e-4c82-9db5-e9c263e16e45', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a279390>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27b510>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '02d8a308-b5e0-447b-a939-7941b6e60821', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a1ef750>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a1edd90>} has insufficient quality\n",
      "face 21939632-12d5-406a-9458-02fd380879c3 added to person 8b7422d7-d933-4bb0-9d56-94a64c3eddd9\n",
      "{'additional_properties': {}, 'face_id': '3723b6ce-6712-403d-a7d0-457b912cd63f', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a278810>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a279910>} has insufficient quality\n",
      "face 211ac93f-41c9-4db2-a198-1dd8846c1464 added to person 8b7422d7-d933-4bb0-9d56-94a64c3eddd9\n",
      "{'additional_properties': {}, 'face_id': 'ee937021-4e0e-4d15-920d-474006b6454d', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a276950>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a276a50>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '357afd09-4a97-4120-869c-100e8068c93d', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b6fd0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b6a10>} has insufficient quality\n",
      "face dd87f909-c986-46d6-a179-84d961d86fbe added to person 8b7422d7-d933-4bb0-9d56-94a64c3eddd9\n",
      "{'additional_properties': {}, 'face_id': '9ca52050-c569-4fcc-8345-f976778cfcff', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1be14d90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1be15150>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '6414c3ca-7798-4a5c-b514-fffc9d83a050', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a3a0210>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a27a8d0>} has insufficient quality\n",
      "face ced4959b-67ea-471b-a99e-99153d967790 added to person f8ada502-ffaa-469d-9908-c70d7efa1853\n",
      "face 3b880f85-b164-4535-a1f8-6154eb4cbffa added to person f8ada502-ffaa-469d-9908-c70d7efa1853\n",
      "face e02e1c5a-7d25-4ddf-bced-c95aa59092c9 added to person f8ada502-ffaa-469d-9908-c70d7efa1853\n",
      "face d7db85db-7d33-44d9-a543-b9acfd4ed20a added to person f8ada502-ffaa-469d-9908-c70d7efa1853\n",
      "{'additional_properties': {}, 'face_id': '3ad0fb38-c15a-4885-801f-10447c8cb69e', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a275010>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a5757d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': 'd5341f16-2cb0-4db6-9be8-beb500576795', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a8488d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a3a2e90>} has insufficient quality\n",
      "face 3e653266-ee35-4a07-a101-900b97d9d929 added to person 07f9191a-69e8-4765-8331-3266987e917b\n",
      "face d4654f11-8eb3-407b-b913-d1113143cc76 added to person 07f9191a-69e8-4765-8331-3266987e917b\n",
      "face 40885d10-f048-4412-a627-bbe4cd50dc00 added to person 07f9191a-69e8-4765-8331-3266987e917b\n",
      "face c823b51e-5887-496b-99c9-2fb728ca6de7 added to person 07f9191a-69e8-4765-8331-3266987e917b\n",
      "{'additional_properties': {}, 'face_id': '32ac8c45-ee15-49ae-ad58-762ae3f1e4f1', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a48bbd0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a489510>} has insufficient quality\n",
      "face 8f0eb332-c409-48a9-9ff3-81a6f97c3f71 added to person 07f9191a-69e8-4765-8331-3266987e917b\n",
      "{'additional_properties': {}, 'face_id': 'b563ecc7-4ba2-4055-9dbb-6369f6664a09', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a479550>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1cd5a490>} has insufficient quality\n",
      "face b2c728ae-7b74-4e54-a437-aade7139175b added to person 07f9191a-69e8-4765-8331-3266987e917b\n",
      "{'additional_properties': {}, 'face_id': 'c7a91d68-4003-437a-a6a1-3f271a50d373', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a4a80d0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a4a8410>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '7912deea-adc4-4d47-9faf-4692a81791f1', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a4b2590>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a4b0fd0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': 'd5858c2f-b734-4dbb-994d-982923988644', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a49b610>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a47b7d0>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': '001fe1d4-ffdd-4b42-91a6-658c653ab1a3', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a492210>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a493990>} has insufficient quality\n",
      "face 4ebef3a9-1129-450a-8f7b-e83744d45d6e added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "face 426e61b5-20bc-48db-bbf6-5e9a19b528b5 added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "face 29ec542b-3a90-4cea-a1e7-0d33d7779880 added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "{'additional_properties': {}, 'face_id': '87d01e3f-148a-4eed-ba21-67ba0516f63d', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a276b90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a274750>} has insufficient quality\n",
      "face 78fdad07-e83e-4f41-bc1c-ed73cd659595 added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "{'additional_properties': {}, 'face_id': '06b41736-d2b3-42fe-8925-02f0a07fa0d3', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29e490>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29fc10>} has insufficient quality\n",
      "face 47a4be8d-dea9-460e-ba2f-f1f067f63dfb added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "face b951062f-6cc9-4257-bbea-d60cf551ce4b added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "{'additional_properties': {}, 'face_id': '0eb6334a-815c-44bf-9d08-2888129d452a', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a4aa850>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a4a8050>} has insufficient quality\n",
      "face 53993300-9344-4790-8652-ff6e02d4ce7e added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "face 1536f164-e9da-4f91-8d5c-2015ce95da00 added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "face 34885287-0852-40e6-8502-c3073abff655 added to person 6667bd63-ec71-4a7d-8f5b-9dfad909266a\n",
      "{'additional_properties': {}, 'face_id': 'e6a620d8-2b54-4b46-b4c9-48398efacc7d', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a250d50>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2537d0>} has insufficient quality\n",
      "face d2bd9529-f202-4122-b8cf-e7281c2477a4 added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n",
      "face a30b824c-12fe-44ed-9bcf-d84c6c072e10 added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n",
      "face d77cbc95-2c67-42b0-a55e-674bc2db7c32 added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n",
      "{'additional_properties': {}, 'face_id': '2e15af6a-7afc-4ead-9219-42378e55ba92', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a48bd90>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a48b610>} has insufficient quality\n",
      "{'additional_properties': {}, 'face_id': 'e3a9144a-a986-48de-b7ab-0131fd9561f3', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a4b2950>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a4b0190>} has insufficient quality\n",
      "face 3bcc508e-7460-4ef8-b086-e13d6474ecf2 added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n",
      "face 2e119e7e-2c94-4e46-b9aa-bf0708e0012f added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n",
      "{'additional_properties': {}, 'face_id': '472a320e-f23d-4b64-b7b5-4d551073a4fd', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a2b4690>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a2b4350>} has insufficient quality\n",
      "face 622e3720-d60d-467f-b93b-9f86ca69a98d added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n",
      "{'additional_properties': {}, 'face_id': '8cff91d6-b4c7-422e-b113-2bdec51db9ff', 'recognition_model': None, 'face_rectangle': <azure.cognitiveservices.vision.face.models._models_py3.FaceRectangle object at 0x7f2b1a29ccd0>, 'face_landmarks': None, 'face_attributes': <azure.cognitiveservices.vision.face.models._models_py3.FaceAttributes object at 0x7f2b1a29e810>} has insufficient quality\n",
      "face 9c63ae39-7dcb-40c0-affb-e86b875efd77 added to person b80001dd-4019-4c23-8c8b-450d9d1442d5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda row: add_faces_to_person(face_client, PERSON_GROUP_ID, row['person_id'], row['faces']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pg resource is nbaplayers\n",
      "<msrest.pipeline.ClientRawResponse object at 0x7f2b1a49b610>\n",
      "Training status: TrainingStatusType.running.\n",
      "\n",
      "Training status: TrainingStatusType.succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "# Train the person group\n",
    "print(\"pg resource is {}\".format(PERSON_GROUP_ID))\n",
    "rawresponse = face_client.person_group.train(PERSON_GROUP_ID, raw= True)\n",
    "print(rawresponse)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying faces in image\n",
      "Person is identified for face ID fbd00eba-d166-46ca-a4e8-93c0daaeaa06 in image, with a confidence of 0.93724.\n",
      "verification result: True. confidence: 0.93724\n"
     ]
    }
   ],
   "source": [
    "# Detect faces\n",
    "face_ids = []\n",
    "\n",
    "local_file = 'extracted_images/image_cropped_3.png'\n",
    "\n",
    "with open(local_file, \"rb\") as f:\n",
    "    faces_local = face_client.face.detect_with_stream(f, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "\n",
    "for face in faces_local:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in image')\n",
    "if not results:\n",
    "    print('No person identified in the person group')\n",
    "for identifiedFace in results:\n",
    "    if len(identifiedFace.candidates) > 0:\n",
    "        print('Person is identified for face ID {} in image, with a confidence of {}.'.format(identifiedFace.face_id, identifiedFace.candidates[0].confidence)) # Get topmost confidence score\n",
    "\n",
    "        # Verify faces\n",
    "        verify_result = face_client.face.verify_face_to_person(identifiedFace.face_id, identifiedFace.candidates[0].person_id, PERSON_GROUP_ID)\n",
    "        print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "        player = df.loc[df['person_id'] == identifiedFace.candidates[0].person_id, 'Player'].values[0]\n",
    "        print(f\"The identified player is: {player}\")\n",
    "    else:\n",
    "        print('No person identified for face ID {} in image.'.format(identifiedFace.face_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
